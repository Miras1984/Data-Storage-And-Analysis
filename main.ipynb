{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_historical_prices(api_key, api_secret, symbol, start_date, end_date):\n",
    "    client = Client(api_key, api_secret)\n",
    "    klines = client.get_historical_klines(symbol, Client.KLINE_INTERVAL_1HOUR, start_date, end_date)\n",
    "    df = pd.DataFrame(klines, columns=['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignored'])\n",
    "    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "    df.set_index('open_time', inplace=True)\n",
    "    df.drop(columns=['ignored'], inplace=True)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T10:23:30.944904600Z",
     "start_time": "2023-05-10T10:23:30.934924400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def get_crypto_data(api_key, api_secret, crypto_list, start_date, end_date):\n",
    "    for symbol in crypto_list:\n",
    "        try:\n",
    "            # Retrieve historical prices for the cryptocurrency\n",
    "            df = get_historical_prices(api_key, api_secret, symbol + 'USDT', start_date, end_date)\n",
    "            df.to_csv(symbol + '.csv')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to retrieve data for {symbol}. Error: {str(e)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T10:23:31.789281200Z",
     "start_time": "2023-05-10T10:23:31.772841200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "binance_api_key = ''\n",
    "binance_secret_key = ''\n",
    "\n",
    "start_date = '2018-05-01'\n",
    "end_date = '2023-05-01'\n",
    "\n",
    "crypto_symbols = ['BTC', 'ETH', 'BNB', 'ADA', 'SOL', 'DOGE']\n",
    "\n",
    "get_crypto_data(binance_api_key, binance_secret_key, crypto_symbols, start_date, end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T10:26:46.878269800Z",
     "start_time": "2023-05-10T10:23:32.465300700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "\n",
    "crypto_data = {}\n",
    "\n",
    "crypto_symbols = ['BTC', 'ETH', 'BNB', 'ADA', 'SOL', 'DOGE']\n",
    "\n",
    "crypto_data['ADA'] = pd.read_csv('/content/drive/MyDrive/ADA.csv')\n",
    "crypto_data['BNB'] = pd.read_csv('/content/drive/MyDrive/BNB.csv')\n",
    "crypto_data['BTC'] = pd.read_csv('/content/drive/MyDrive/BTC.csv')\n",
    "crypto_data['DOGE'] = pd.read_csv('/content/drive/MyDrive/DOGE.csv')\n",
    "crypto_data['ETH'] = pd.read_csv('/content/drive/MyDrive/ETH.csv')\n",
    "crypto_data['SOL'] = pd.read_csv('/content/drive/MyDrive/SOL.csv')\n",
    "\n",
    "# Step 1: Data Cleaning and Formatting\n",
    "def clean_data(df):\n",
    "    df['open_time'] = pd.to_datetime(df['open_time'], unit='ns').dt.floor('ns').dt.tz_localize(pytz.utc)\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ns').dt.floor('ns').dt.tz_localize(pytz.utc)\n",
    "\n",
    "    df = df[['open_time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df = df.set_index('date')\n",
    "    df = df.sort_index()\n",
    "    df = df.fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "for symbol in crypto_symbols:\n",
    "    df = crypto_data[symbol]\n",
    "    df = clean_data(df)\n",
    "    crypto_data[symbol] = df\n",
    "\n",
    "# Step 2: Technical Indicator Creation\n",
    "def create_technical_indicators(df):\n",
    "    df['daily_return'] = df['close'].pct_change()\n",
    "    df['ma_7'] = ta.volatility.bollinger_mavg(df['close'], window=7)\n",
    "    df['ma_14'] = ta.volatility.bollinger_mavg(df['close'], window=14)\n",
    "    df['ma_21'] = ta.volatility.bollinger_mavg(df['close'], window=21)\n",
    "    df['rsi_7'] = ta.momentum.rsi(df['close'], window=7)\n",
    "    df['rsi_14'] = ta.momentum.rsi(df['close'], window=14)\n",
    "    df['rsi_21'] = ta.momentum.rsi(df['close'], window=21)\n",
    "    df['lower_band'] = ta.volatility.bollinger_lband(df['close'], window=20, window_dev=2)\n",
    "    df['upper_band'] = ta.volatility.bollinger_hband(df['close'], window=20, window_dev=2)\n",
    "    df['middle_band'] = ta.volatility.bollinger_mavg(df['close'], window=20)\n",
    "    df['stoch'] = ta.momentum.stoch(df['high'], df['low'], df['close'], window=14, smooth_window=3)\n",
    "    macd = ta.trend.macd(df['close'], window_slow=26, window_fast=12)\n",
    "    signal_line = macd.ewm(span=9, adjust=False).mean()\n",
    "    histogram = macd - signal_line\n",
    "\n",
    "    df['macd'] = macd\n",
    "    df['signal_line'] = signal_line\n",
    "    df['histogram'] = histogram\n",
    "\n",
    "    return df\n",
    "\n",
    "for symbol in crypto_symbols:\n",
    "    df = crypto_data[symbol]\n",
    "    df = create_technical_indicators(df)\n",
    "    crypto_data[symbol] = df\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "def create_features(df):\n",
    "    df['open_trend'] = df['open'] - df['close'].shift(1)\n",
    "    df['close_trend'] = df['close'] - df['close'].shift(1)\n",
    "    df['high_trend'] = df['high'] - df['high'].shift(1)\n",
    "    df['low_trend'] = df['low'] - df['low'].shift(1)\n",
    "    df['volume_trend'] = df['volume'] - df['volume'].shift(1)\n",
    "    df['return_trend'] = df['daily_return'] - df['daily_return'].shift(1)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "for symbol in crypto_symbols:\n",
    "    df = crypto_data[symbol]\n",
    "    df = create_features(df)\n",
    "    crypto_data[symbol] = df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "crypto_data['BTC']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T10:38:28.408241400Z",
     "start_time": "2023-05-10T10:38:28.387808500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# create a PySpark session\n",
    "spark = SparkSession.builder.appName('CryptoReturn').getOrCreate()\n",
    "\n",
    "# set the list of cryptocurrencies to predict\n",
    "crypto_symbols = ['BTC', 'ETH', 'BNB', 'ADA', 'SOL', 'DOGE']\n",
    "\n",
    "# create a list to hold the trained models\n",
    "models = []\n",
    "\n",
    "# loop through each cryptocurrency\n",
    "for symbol in crypto_symbols:\n",
    "    # get the cleaned and feature engineered data for this cryptocurrency\n",
    "    df = crypto_data[symbol]\n",
    "\n",
    "    # define the feature columns\n",
    "    feature_cols = ['open', 'high', 'low', 'close', 'volume', 'ma_7', 'ma_14', 'ma_21', 'rsi_7', 'rsi_14', 'rsi_21', 'lower_band', 'upper_band', 'middle_band', 'stoch', 'macd', 'signal_line', 'histogram', 'open_trend', 'close_trend', 'high_trend', 'low_trend', 'volume_trend', 'return_trend']\n",
    "\n",
    "    # create a PySpark DataFrame from the data\n",
    "    spark_df = spark.createDataFrame(df.reset_index())\n",
    "\n",
    "    # create a VectorAssembler to combine the feature columns into a single vector column\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "\n",
    "    # scale the features\n",
    "    scaler = MinMaxScaler(inputCol='features', outputCol='scaled_features')\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    training_data, testing_data = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "    # create a GBTRegressor model\n",
    "    gbt = GBTRegressor(featuresCol='scaled_features', labelCol='daily_return', maxDepth=5, maxBins=32, maxIter=20)\n",
    "\n",
    "    # create a pipeline to run the feature engineering and model training steps\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, gbt])\n",
    "\n",
    "    # create a grid of hyperparameters to search over\n",
    "    param_grid = ParamGridBuilder() \\\n",
    "        .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "        .addGrid(gbt.maxBins, [32, 64]) \\\n",
    "        .build()\n",
    "\n",
    "    # create a cross validator to search over the hyperparameter grid and evaluate the model performance\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol='daily_return')\n",
    "    cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "    # train the model using the training data and the cross validator\n",
    "    cv_model = cv.fit(training_data)\n",
    "\n",
    "    # evaluate the model on the testing data\n",
    "    predictions = cv_model.transform(testing_data)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    accuracy = 1 - rmse\n",
    "    # print the accuracy for the model\n",
    "    print(f'{symbol}: Accuracy = {accuracy}')\n",
    "\n",
    "    # add the trained model to the list of models\n",
    "    models.append((symbol, cv_model))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
